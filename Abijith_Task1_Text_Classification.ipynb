{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-12T17:40:04.699231400Z",
     "start_time": "2023-11-12T17:39:23.307757700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abhis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "11314 documents\n",
      "20 categories\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_16636\\1220773149.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m     78\u001B[0m         \u001B[1;31m# Evaluate on the test set\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     79\u001B[0m         \u001B[0mpredictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     80\u001B[0m         \u001B[0mtest_accuracy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maccuracy_score\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpredictions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     81\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 82\u001B[1;33m         results_table = results_table.append({\n\u001B[0m\u001B[0;32m     83\u001B[0m             \u001B[1;34m'Feature Extractor'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mextractor_name\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     84\u001B[0m             \u001B[1;34m'Classifier'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mclf_name\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m             \u001B[1;34m'Accuracy'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mtest_accuracy\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   6198\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_accessors\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6199\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6200\u001B[0m         ):\n\u001B[0;32m   6201\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 6202\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "print(newsgroups.target_names)\n",
    "categories = newsgroups.target_names\n",
    "data = fetch_20newsgroups(subset='train', categories=categories)\n",
    "print(f\"{len(data.filenames)} documents\")\n",
    "print(f\"{len(data.target_names)} categories\")\n",
    "print()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.25, random_state=42)\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text.lower())\n",
    "feature_extractors = [\n",
    "    ('CountVectorizer', CountVectorizer()),\n",
    "    ('TfidfVectorizer', TfidfVectorizer()),\n",
    "    ('Word2Vec', Word2Vec(sentences=[tokenize_text(doc) for doc in X_train], vector_size=100, window=5, min_count=1, workers=4)),\n",
    "    ('Doc2Vec', Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=10))\n",
    "]\n",
    "classifiers = [\n",
    "    ('Multinomial Naive Bayes', MultinomialNB()),\n",
    "    ('Logistic Regression', LogisticRegression()),\n",
    "    ('Support Vector Machines', SVC()),\n",
    "    ('Decision Trees', DecisionTreeClassifier())\n",
    "]\n",
    "results_table = pd.DataFrame(columns=['Feature Extractor', 'Classifier', 'Accuracy', 'Best Params'])\n",
    "\n",
    "for extractor_name, extractor_model in feature_extractors:\n",
    "    for clf_name, clf_model in classifiers:\n",
    "        pipeline = Pipeline([\n",
    "            ('vect', extractor_model),\n",
    "            ('clf', clf_model),\n",
    "        ])\n",
    "        \n",
    "        # Define the parameter grid for grid search\n",
    "        param_grid = {}\n",
    "        \n",
    "        # For Multinomial Naive Bayes, add 'alpha' to the parameter grid\n",
    "        if 'Multinomial' in clf_name:\n",
    "            param_grid['clf__alpha'] = [0.1, 0.5, 1.0]\n",
    "\n",
    "        # For Logistic Regression, add 'C' to the parameter grid\n",
    "        if 'Logistic' in clf_name:\n",
    "            param_grid['clf__C'] = [0.1, 1, 10]\n",
    "\n",
    "        # Add other classifier-specific parameters as needed\n",
    "        \n",
    "        # Create GridSearchCV object\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        \n",
    "        # Fit the grid search to the data\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get the best parameters and accuracy\n",
    "        best_params = grid_search.best_params_\n",
    "        best_accuracy = grid_search.best_score_\n",
    "\n",
    "        # Fit the pipeline with the best parameters on the entire training set\n",
    "        pipeline.set_params(**best_params)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate on the test set\n",
    "        predictions = pipeline.predict(X_test)\n",
    "        test_accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "\n",
    "        results_table = results_table.append({\n",
    "            'Feature Extractor': extractor_name,\n",
    "            'Classifier': clf_name,\n",
    "            'Accuracy': test_accuracy,\n",
    "            'Best Params': best_params\n",
    "        }, ignore_index=True)\n",
    "\n",
    "best_config = results_table.loc[results_table['Accuracy'].idxmax()]\n",
    "results_table.to_csv('Abijith_Task1_Text_Classification_GridSearchCV.txt', index=False, sep='\\t')\n",
    "print(\"Best Configuration:\")\n",
    "print(best_config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
